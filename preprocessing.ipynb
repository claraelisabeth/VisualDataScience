{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name\n",
    "\n",
    "## Visual Data Science\n",
    "\n",
    "Clara Pichler, 11917694\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Introduction\n",
    "- Original Research Questions\n",
    "- Used Datasets\n",
    "- Requirements & Dependencies\n",
    "\n",
    "2. Data Preprocessing\n",
    "- Loading in the Data Sets\n",
    "- First Steps\n",
    "- Missing Values\n",
    "- Merging Data Sets\n",
    "\n",
    "3. Data Exploration\n",
    "- \n",
    "\n",
    "4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Bis 16.12\n",
    "\n",
    "__Wrangle:__ \n",
    "- Join the two or more datasets you selected into one big data table, and\n",
    "- Solve issues like formatting issues, missing data, faulty values, and non-matching keys\n",
    "- _10 points_ extra, if you can (visually!) show and explain the data quality of your dataset (for example, before and after cleaning steps). There are no instructions how such a visualization should look like, since this also highly depends on the chosen domain and data. You will have to come up with your own, creative, solution here.\n",
    "\n",
    "__Profile:__\n",
    "- Find at least 3 valuable insights.\n",
    "- Show the insights by using visualization.\n",
    "\n",
    "In the Profile part, you will have to explore the data in detail, to completely understand its structure, and to discover any interesting patterns that can be found in there. The following steps are required:\n",
    "\n",
    "- Find at least 3 informative insights in your dataset, and\n",
    "- Show and explain the insights using visualizations (one visualization per insight).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Original Research Questions\n",
    "\n",
    "- Are there any similarities between countries which win medals often in specific kinds of sports?\n",
    "- Which factors influence the amount of medals a country wins? \n",
    "- Is it possible to predict the number of won medals of a country?\n",
    "- Are there any trends in the medal distribution over time?\n",
    "- Which factors play a part in the \"under-dog\" countries winning suddenly some medals?\n",
    "\n",
    "\n",
    "### Used Data Sets\n",
    "\n",
    "__Olympics Medals Data Set__\n",
    "- _description:_ General information on medalists (Athlete or Team)\n",
    "- _source:_ https://www.kaggle.com/datasets/piterfm/olympic-games-medals-19862018\n",
    "- _note:_ This data set comes with three other data sets that include information on the athletes, hosts and all of the results. I will only focus on the medals so first, second and third place, therefore only using the `olympic_medals.csv` data set. \n",
    "- _disadvantages:_ Quote from the description\n",
    "    - \"There are no results for qualification rounds. For instance, event 100-m men contains only final results without semi-finals and other hits.\"\n",
    "    - \"There is no information about athletes for team competitions that consist of more than 2 participants. Only team records.\"\n",
    "\n",
    "__Rugged Data Set__\n",
    "- _description:_\n",
    "- _source:_ https://diegopuga.org/data/rugged/ \n",
    "- \n",
    "\n",
    "__Elevation Extremes Data Set__\n",
    "- _description:_ A sortable table which lists land surface elevation extremes by country or dependent territory\n",
    "- _source:_ https://en.wikipedia.org/wiki/List_of_elevation_extremes_by_country \n",
    "- \n",
    "\n",
    "### Requirements & Dependencies\n",
    "\n",
    "This project was created using Python 3.12.5. The exact versions of the dependencies can be installed with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as r\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "### Loading in the Data Sets\n",
    "\n",
    "First and foremost we will load in our data sets. For the rugged data I had some problems with encoding since two countries have special characters in their name, as one can see below. By using `encoding='latin1'` this issue was able to be resolved.\n",
    "\n",
    "For the elevation data set which I got from Wikipedia, I used `BeautifulSoup` to scrape the table from their website. I treid firts `pd.read_html` however this simple approach did not work for me like it did for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/rugged_data/rugged_data.csv', 'r', encoding='ascii', errors='replace') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if 'ï¿½' in line:  \n",
    "            print(f\"Problem in row {i + 1}: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics = pd.read_csv('data/olympics/olympic_medals.csv')\n",
    "df_rugged = pd.read_csv('data/rugged_data/rugged_data.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_elevation_extremes_by_country\"\n",
    "response = r.get(url)\n",
    "wiki_page_text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code # 200 means everything is A-OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(wiki_page_text, 'html.parser')\n",
    "elevation_table = soup.find('table',{'class':'wikitable sortable'})\n",
    "\n",
    "headers = [header.text.strip() for header in elevation_table.find_all('th')]\n",
    "\n",
    "rows = []\n",
    "for row in elevation_table.find_all('tr')[1:]:  \n",
    "    cells = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
    "    rows.append(cells)\n",
    "\n",
    "df_elevation = pd.DataFrame(rows, columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will take a first look at the `df_olympics` dataframe. We will drop unnecessary columns like `athlete_url` and `country_code` since we only need the ISO code which is the `country_3_letter_code` attribute. I do not care about the host country so I changed the `slug_game` attribute to `year` and left out the host name. The type was changed to `int`, all other types are fine. Maybe we will change `medal_type` gold, silver and bronze to 1, 2, and 3 in the future for making it easier to work with. \n",
    "\n",
    "I also drop the column `athlete_full_name` which will result in rows that are not unique since for events with the `participant_type` `GameTeam` we have a medal entry for each athlete in the team. Thats why I use `drop_duplicates()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics = df_olympics.drop(['athlete_url', 'country_code', 'athlete_full_name'], axis=1).drop_duplicates()\n",
    "\n",
    "df_olympics = df_olympics.rename(columns={\n",
    "    'slug_game': 'year',\n",
    "    'country_3_letter_code': 'isocode'\n",
    "})\n",
    "\n",
    "df_olympics['year'] = df_olympics['year'].str[-4:].astype(int)\n",
    "\n",
    "df_olympics = df_olympics.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>year</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_gender</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>participant_title</th>\n",
       "      <th>country_name</th>\n",
       "      <th>isocode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curling</td>\n",
       "      <td>2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Italy</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curling</td>\n",
       "      <td>2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curling</td>\n",
       "      <td>2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curling</td>\n",
       "      <td>2022</td>\n",
       "      <td>Women</td>\n",
       "      <td>Women</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curling</td>\n",
       "      <td>2022</td>\n",
       "      <td>Women</td>\n",
       "      <td>Women</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discipline_title  year    event_title event_gender medal_type  \\\n",
       "0          Curling  2022  Mixed Doubles        Mixed       GOLD   \n",
       "1          Curling  2022  Mixed Doubles        Mixed     SILVER   \n",
       "2          Curling  2022  Mixed Doubles        Mixed     BRONZE   \n",
       "3          Curling  2022          Women        Women       GOLD   \n",
       "4          Curling  2022          Women        Women     SILVER   \n",
       "\n",
       "  participant_type participant_title   country_name isocode  \n",
       "0         GameTeam             Italy          Italy     ITA  \n",
       "1         GameTeam            Norway         Norway     NOR  \n",
       "2         GameTeam            Sweden         Sweden     SWE  \n",
       "3         GameTeam     Great Britain  Great Britain     GBR  \n",
       "4         GameTeam             Japan          Japan     JPN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20178 entries, 0 to 20177\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   discipline_title   20178 non-null  object\n",
      " 1   year               20178 non-null  int64 \n",
      " 2   event_title        20178 non-null  object\n",
      " 3   event_gender       20178 non-null  object\n",
      " 4   medal_type         20178 non-null  object\n",
      " 5   participant_type   20178 non-null  object\n",
      " 6   participant_title  5104 non-null   object\n",
      " 7   country_name       20178 non-null  object\n",
      " 8   isocode            20178 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022 2020 2018 2016 2014 2012 2010 2008 2006 2004 2002 2000 1998 1996\n",
      " 1994 1992 1988 1984 1980 1976 1972 1968 1964 1960 1956 1952 1948 1936\n",
      " 1932 1928 1924 1920 1912 1908 1904 1900 1896]\n"
     ]
    }
   ],
   "source": [
    "display(df_olympics.head(5))\n",
    "display(df_olympics.info())\n",
    "print(df_olympics['year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on with `df_elevation`. The attributes `Continent`, `Highest point` and `Lowest point` ist non of my interest from this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elevation = df_elevation.drop(['Continent', 'Highest point', 'Lowest point'], axis=1)\n",
    "\n",
    "df_elevation = df_elevation.rename(columns={\n",
    "    'Country or region': 'country_name',\n",
    "    'Maximum elevation': 'max_elevation',\n",
    "    'Minimum elevation': 'min_elevation',\n",
    "    'Elevation span' : 'elevation_span'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elevation = df_elevation.replace(\"sea level\", \"0\")\n",
    "\n",
    "for col in ['max_elevation', 'min_elevation', 'elevation_span']: \n",
    "    df_elevation[col] = (df_elevation[col].str.split('m')\n",
    "                         .str[0].str.strip()\n",
    "                         .str.replace('â', '-', regex=False)\n",
    "                         .str.replace(',', '.', regex=False))\n",
    "    df_elevation.replace({col : ''}, np.nan, inplace=True)\n",
    "    df_elevation[col] = df_elevation[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>elevation_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>7492.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>7234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>3043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country_name  max_elevation  min_elevation  elevation_span\n",
       "0     Afghanistan         7492.0          258.0          7234.0\n",
       "1         Albania         2764.0            0.0          2764.0\n",
       "2         Algeria         3003.0          -40.0          3043.0\n",
       "3  American Samoa          966.0            0.0           966.0\n",
       "4         Andorra         2942.0          840.0          2102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_elevation.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward to `df_rugged`. It has so much data and so much potential. I will only use some of the many attributes it provides so that this project won't take forever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rugged = df_rugged[['isocode', 'rugged', 'rugged_popw', 'rugged_slope',\n",
    "       'rugged_lsd', 'rugged_pc', \n",
    "       'land_area', # Units are thousands of hectares\n",
    "       'lat', 'lon', 'soil', \n",
    "       'desert', # % Desert: sandy desert, dunes, rocky or lava flows\n",
    "       'tropical', # % Tropical climate\n",
    "       'dist_coast', 'near_coast', # % Within 100 km of ice-free coast\n",
    "       'gemstones', 'rgdppc_2000',\n",
    "       'rgdppc_1950_m', 'rgdppc_1975_m', 'rgdppc_2000_m', 'rgdppc_1950_2000_m',\n",
    "       'q_rule_law', 'cont_africa', 'cont_asia', 'cont_europe', 'cont_oceania',\n",
    "       'cont_north_america', 'cont_south_america', 'legor_gbr', 'legor_fra',\n",
    "       'legor_soc', 'legor_deu', 'legor_sca', 'colony_esp', 'colony_gbr',\n",
    "       'colony_fra', 'colony_prt', 'colony_oeu', 'africa_region_n',\n",
    "       'africa_region_s', 'africa_region_w', 'africa_region_e',\n",
    "       'africa_region_c', 'slave_exports', 'dist_slavemkt_atlantic',\n",
    "       'dist_slavemkt_indian', 'dist_slavemkt_saharan', 'dist_slavemkt_redsea',\n",
    "       'pop_1400', 'european_descent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isocode</th>\n",
       "      <th>isonum</th>\n",
       "      <th>country</th>\n",
       "      <th>rugged</th>\n",
       "      <th>rugged_popw</th>\n",
       "      <th>rugged_slope</th>\n",
       "      <th>rugged_lsd</th>\n",
       "      <th>rugged_pc</th>\n",
       "      <th>land_area</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>africa_region_w</th>\n",
       "      <th>africa_region_e</th>\n",
       "      <th>africa_region_c</th>\n",
       "      <th>slave_exports</th>\n",
       "      <th>dist_slavemkt_atlantic</th>\n",
       "      <th>dist_slavemkt_indian</th>\n",
       "      <th>dist_slavemkt_saharan</th>\n",
       "      <th>dist_slavemkt_redsea</th>\n",
       "      <th>pop_1400</th>\n",
       "      <th>european_descent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>533</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.226</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.508</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>614.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2.518</td>\n",
       "      <td>1.469</td>\n",
       "      <td>7.414</td>\n",
       "      <td>0.720</td>\n",
       "      <td>39.004</td>\n",
       "      <td>65209.0</td>\n",
       "      <td>33.833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1870829.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGO</td>\n",
       "      <td>24</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.714</td>\n",
       "      <td>2.274</td>\n",
       "      <td>0.228</td>\n",
       "      <td>4.906</td>\n",
       "      <td>124670.0</td>\n",
       "      <td>-12.299</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3610000.0</td>\n",
       "      <td>5.669</td>\n",
       "      <td>6.981</td>\n",
       "      <td>4.926</td>\n",
       "      <td>3.872</td>\n",
       "      <td>1223208.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIA</td>\n",
       "      <td>660</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.231</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>Albania</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.597</td>\n",
       "      <td>10.451</td>\n",
       "      <td>1.006</td>\n",
       "      <td>62.133</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>41.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  isocode  isonum      country  rugged  rugged_popw  rugged_slope  rugged_lsd  \\\n",
       "0     ABW     533        Aruba   0.462        0.380         1.226       0.144   \n",
       "1     AFG       4  Afghanistan   2.518        1.469         7.414       0.720   \n",
       "2     AGO      24       Angola   0.858        0.714         2.274       0.228   \n",
       "3     AIA     660     Anguilla   0.013        0.010         0.026       0.006   \n",
       "4     ALB       8      Albania   3.427        1.597        10.451       1.006   \n",
       "\n",
       "   rugged_pc  land_area     lat  ...  africa_region_w  africa_region_e  \\\n",
       "0      0.000       18.0  12.508  ...                0                0   \n",
       "1     39.004    65209.0  33.833  ...                0                0   \n",
       "2      4.906   124670.0 -12.299  ...                0                0   \n",
       "3      0.000        9.0  18.231  ...                0                0   \n",
       "4     62.133     2740.0  41.143  ...                0                0   \n",
       "\n",
       "   africa_region_c  slave_exports  dist_slavemkt_atlantic  \\\n",
       "0                0            0.0                     NaN   \n",
       "1                0            0.0                     NaN   \n",
       "2                1      3610000.0                   5.669   \n",
       "3                0            0.0                     NaN   \n",
       "4                0            0.0                     NaN   \n",
       "\n",
       "   dist_slavemkt_indian  dist_slavemkt_saharan  dist_slavemkt_redsea  \\\n",
       "0                   NaN                    NaN                   NaN   \n",
       "1                   NaN                    NaN                   NaN   \n",
       "2                 6.981                  4.926                 3.872   \n",
       "3                   NaN                    NaN                   NaN   \n",
       "4                   NaN                    NaN                   NaN   \n",
       "\n",
       "    pop_1400  european_descent  \n",
       "0      614.0               NaN  \n",
       "1  1870829.0               0.0  \n",
       "2  1223208.0               2.0  \n",
       "3        NaN               NaN  \n",
       "4   200000.0             100.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Data columns (total 51 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   isocode                 234 non-null    object \n",
      " 1   isonum                  234 non-null    int64  \n",
      " 2   country                 234 non-null    object \n",
      " 3   rugged                  234 non-null    float64\n",
      " 4   rugged_popw             234 non-null    float64\n",
      " 5   rugged_slope            234 non-null    float64\n",
      " 6   rugged_lsd              234 non-null    float64\n",
      " 7   rugged_pc               234 non-null    float64\n",
      " 8   land_area               230 non-null    float64\n",
      " 9   lat                     234 non-null    float64\n",
      " 10  lon                     234 non-null    float64\n",
      " 11  soil                    225 non-null    float64\n",
      " 12  desert                  234 non-null    float64\n",
      " 13  tropical                234 non-null    float64\n",
      " 14  dist_coast              234 non-null    float64\n",
      " 15  near_coast              234 non-null    float64\n",
      " 16  gemstones               234 non-null    int64  \n",
      " 17  rgdppc_2000             170 non-null    float64\n",
      " 18  rgdppc_1950_m           137 non-null    float64\n",
      " 19  rgdppc_1975_m           137 non-null    float64\n",
      " 20  rgdppc_2000_m           159 non-null    float64\n",
      " 21  rgdppc_1950_2000_m      137 non-null    float64\n",
      " 22  q_rule_law              197 non-null    float64\n",
      " 23  cont_africa             234 non-null    int64  \n",
      " 24  cont_asia               234 non-null    int64  \n",
      " 25  cont_europe             234 non-null    int64  \n",
      " 26  cont_oceania            234 non-null    int64  \n",
      " 27  cont_north_america      234 non-null    int64  \n",
      " 28  cont_south_america      234 non-null    int64  \n",
      " 29  legor_gbr               211 non-null    float64\n",
      " 30  legor_fra               211 non-null    float64\n",
      " 31  legor_soc               211 non-null    float64\n",
      " 32  legor_deu               211 non-null    float64\n",
      " 33  legor_sca               211 non-null    float64\n",
      " 34  colony_esp              234 non-null    int64  \n",
      " 35  colony_gbr              234 non-null    int64  \n",
      " 36  colony_fra              234 non-null    int64  \n",
      " 37  colony_prt              234 non-null    int64  \n",
      " 38  colony_oeu              234 non-null    int64  \n",
      " 39  africa_region_n         234 non-null    int64  \n",
      " 40  africa_region_s         234 non-null    int64  \n",
      " 41  africa_region_w         234 non-null    int64  \n",
      " 42  africa_region_e         234 non-null    int64  \n",
      " 43  africa_region_c         234 non-null    int64  \n",
      " 44  slave_exports           234 non-null    float64\n",
      " 45  dist_slavemkt_atlantic  57 non-null     float64\n",
      " 46  dist_slavemkt_indian    57 non-null     float64\n",
      " 47  dist_slavemkt_saharan   57 non-null     float64\n",
      " 48  dist_slavemkt_redsea    57 non-null     float64\n",
      " 49  pop_1400                201 non-null    float64\n",
      " 50  european_descent        165 non-null    float64\n",
      "dtypes: float64(31), int64(18), object(2)\n",
      "memory usage: 93.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['isocode', 'isonum', 'country', 'rugged', 'rugged_popw', 'rugged_slope',\n",
       "       'rugged_lsd', 'rugged_pc', 'land_area', 'lat', 'lon', 'soil', 'desert',\n",
       "       'tropical', 'dist_coast', 'near_coast', 'gemstones', 'rgdppc_2000',\n",
       "       'rgdppc_1950_m', 'rgdppc_1975_m', 'rgdppc_2000_m', 'rgdppc_1950_2000_m',\n",
       "       'q_rule_law', 'cont_africa', 'cont_asia', 'cont_europe', 'cont_oceania',\n",
       "       'cont_north_america', 'cont_south_america', 'legor_gbr', 'legor_fra',\n",
       "       'legor_soc', 'legor_deu', 'legor_sca', 'colony_esp', 'colony_gbr',\n",
       "       'colony_fra', 'colony_prt', 'colony_oeu', 'africa_region_n',\n",
       "       'africa_region_s', 'africa_region_w', 'africa_region_e',\n",
       "       'africa_region_c', 'slave_exports', 'dist_slavemkt_atlantic',\n",
       "       'dist_slavemkt_indian', 'dist_slavemkt_saharan', 'dist_slavemkt_redsea',\n",
       "       'pop_1400', 'european_descent'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_rugged.head(5))\n",
    "display(df_rugged.info())\n",
    "display(df_rugged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
